{
  "title": "Settings",
  "nav.assistants": "Assistants",
  "nav.models": "Models",
  "nav.providers": "Providers",
  "nav.knowledgeBases": "Knowledge Bases",
  "nav.promptTemplates": "Prompt Templates",
  "nav.ragSettings": "RAG Settings",
  "nav.search": "Search",
  "nav.webpage": "Webpage",
  "nav.titleGeneration": "Title Generation",
  "nav.followup": "Follow-up Questions",
  "nav.compression": "Compression",
  "nav.fileReference": "File Reference",
  "nav.translation": "Translation",
  "nav.tts": "Text-to-Speech",
  "nav.developer": "Developer",
  "nav.memory": "Memory",
  "memory.title": "Memory",
  "memory.pageDescription": "Settings toggles plus full memory visualization in one place.",
  "memory.loadingDescription": "Loading memory settings...",
  "memory.loading": "Loading...",
  "memory.sections.switches": "Memory Switches",
  "memory.sections.createItem": "Create Memory Item",
  "memory.sections.visualization": "Memory Visualization",
  "memory.sections.searchContext": "Search Context",
  "memory.sections.rawMetadata": "Raw metadata JSON",
  "memory.fields.enableMemory": "Enable memory",
  "memory.fields.enableGlobalScope": "Enable global scope",
  "memory.fields.enableAssistantScope": "Enable assistant scope",
  "memory.fields.enableAutoExtraction": "Enable auto extraction",
  "memory.fields.profileId": "Profile ID",
  "memory.fields.collection": "Collection",
  "memory.fields.topK": "Top K",
  "memory.fields.threshold": "Threshold",
  "memory.fields.maxInjected": "Max Injected",
  "memory.fields.maxItemLength": "Max Item Length",
  "memory.fields.minTextLength": "Min Text Length",
  "memory.fields.maxItemsPerTurn": "Max Items Per Turn",
  "memory.fields.enabledLayers": "Enabled Layers",
  "memory.fields.pinned": "Pinned",
  "memory.fields.confidence": "Confidence",
  "memory.fields.importance": "Importance",
  "memory.fields.sessionSource": "Session Source",
  "memory.fields.messageSource": "Message Source",
  "memory.fields.showInactive": "Show inactive memories",
  "memory.fields.showMetadataJson": "Show full metadata JSON",
  "memory.fields.content": "Content",
  "memory.layers.fact": "Fact",
  "memory.layers.instruction": "Instruction",
  "memory.options.scopeGlobal": "global",
  "memory.options.scopeAssistant": "assistant",
  "memory.options.assistant": "assistant",
  "memory.options.allScopes": "all scopes",
  "memory.options.allAssistants": "all assistants",
  "memory.options.allLayers": "all layers",
  "memory.options.sortUpdated": "updated desc",
  "memory.options.sortCreated": "created desc",
  "memory.options.sortScore": "score desc",
  "memory.options.sortImportance": "importance desc",
  "memory.options.sortConfidence": "confidence desc",
  "memory.options.sortHit": "hit count desc",
  "memory.placeholders.content": "Full memory content",
  "memory.placeholders.search": "Search content / id / hash / metadata",
  "memory.stats.visibleWithCount": "Visible: {{visible}} / API Count: {{count}}",
  "memory.stats.total": "Total",
  "memory.stats.active": "Active",
  "memory.stats.inactive": "Inactive",
  "memory.stats.pinned": "Pinned",
  "memory.stats.global": "Global",
  "memory.stats.assistant": "Assistant",
  "memory.actions.refresh": "Refresh",
  "memory.actions.saveSettings": "Save Settings",
  "memory.actions.saving": "Saving...",
  "memory.actions.create": "Create",
  "memory.actions.creating": "Creating...",
  "memory.actions.apply": "Apply",
  "memory.actions.loading": "Loading...",
  "memory.actions.pin": "Pin",
  "memory.actions.unpin": "Unpin",
  "memory.actions.activate": "Activate",
  "memory.actions.deactivate": "Deactivate",
  "memory.actions.delete": "Delete",
  "memory.messages.settingsUpdated": "Memory settings updated",
  "memory.messages.itemCreated": "Memory item created",
  "memory.messages.itemDeleted": "Memory item deleted",
  "memory.messages.statusUpdated": "Memory status updated",
  "memory.messages.pinUpdated": "Memory pin status updated",
  "memory.messages.confirmDelete": "Delete memory {{id}}?",
  "memory.errors.loadSettings": "Failed to load memory settings",
  "memory.errors.loadList": "Failed to load memories",
  "memory.errors.saveSettings": "Failed to save memory settings",
  "memory.errors.contentRequired": "Memory content is required",
  "memory.errors.assistantRequired": "Please select assistant for assistant scope",
  "memory.errors.createItem": "Failed to create memory",
  "memory.errors.deleteItem": "Failed to delete memory",
  "memory.errors.updateItem": "Failed to update memory",
  "memory.badges.active": "active",
  "memory.badges.inactive": "inactive",
  "memory.badges.pinned": "pinned",
  "memory.badges.notPinned": "not pinned",
  "memory.empty": "No memories found.",
  "memory.meta.assistant": "assistant",
  "memory.meta.profileId": "profile_id",
  "memory.meta.score": "score",
  "memory.meta.confidence": "confidence",
  "memory.meta.importance": "importance",
  "memory.meta.hitCount": "hit_count",
  "memory.meta.hash": "hash",
  "memory.meta.sourceSession": "source_session",
  "memory.meta.sourceMessage": "source_message",
  "memory.meta.createdAt": "created_at",
  "memory.meta.updatedAt": "updated_at",
  "memory.meta.lastHitAt": "last_hit_at",

  "crud.confirmDelete": "Are you sure you want to delete \"{{name}}\"?",
  "crud.deletedSuccess": "{{item}} deleted successfully",
  "crud.defaultUpdated": "Default {{item}} updated",
  "crud.requiredField": "Please fill in required field: {{field}}",
  "crud.fieldError": "{{field}}: {{error}}",
  "crud.updatedSuccess": "{{item}} updated successfully",
  "crud.createdSuccess": "{{item}} created successfully",
  "crud.loadingItems": "Loading {{items}}...",
  "crud.addItem": "Add {{item}}",
  "crud.editItem": "Edit {{item}}",
  "crud.alreadyDefault": "Already default",
  "crud.setAsDefault": "Set as default",
  "crud.cannotDeleteDefault": "Cannot delete default item",
  "crud.searchItems": "Search {{items}}...",
  "crud.noItemsFound": "No {{items}} found",
  "crud.notFound": "{{item}} not found",
  "crud.editingItem": "Editing {{name}}",

  "config.failedToLoad": "Failed to load configuration",
  "config.savedSuccess": "Settings saved successfully!",
  "config.failedToSave": "Failed to save configuration",
  "config.loadingSettings": "Loading settings...",
  "config.saveSettings": "Save Settings",

  "formField.unknownType": "Unknown field type",
  "formField.clickToChooseIcon": "Click to choose an icon",
  "formField.searchIcons": "Search icons...",
  "formField.iconsFound": "{{count}} icons found",
  "formField.iconsAvailable": "{{count}} icons available",
  "formField.loadMore": "Load more ({{count}} remaining)",

  "developer.title": "Developer Settings",
  "developer.description": "Enable developer tools for inspecting chunking and RAG behavior",
  "developer.modeTitle": "Developer Mode",
  "developer.modeDescription": "Show developer tools in the main navigation and allow chunk inspection.",

  "knowledgeBase.updatedSuccess": "Knowledge base updated successfully",
  "knowledgeBase.loading": "Loading knowledge base...",
  "knowledgeBase.notFound": "Knowledge base not found",
  "knowledgeBase.editTitle": "Edit Knowledge Base",
  "knowledgeBase.editingName": "Editing {{name}}",

  "documents.pending": "Pending",
  "documents.processing": "Processing",
  "documents.ready": "Ready",
  "documents.error": "Error",
  "documents.failedToLoad": "Failed to load documents",
  "documents.uploadFailed": "Upload failed",
  "documents.confirmDelete": "Delete this document? This will also remove its chunks from the vector store.",
  "documents.failedToDelete": "Failed to delete document",
  "documents.failedToReprocess": "Failed to reprocess document",
  "documents.noDocsForReprocess": "No documents available for reprocessing.",
  "documents.confirmReprocessAll": "Reprocess all documents? This will rebuild chunks for the current knowledge base.",
  "documents.failedToReprocessAll": "Failed to reprocess documents",
  "documents.title": "Documents",
  "documents.reprocessing": "Reprocessing...",
  "documents.reprocessAll": "Reprocess All",
  "documents.uploading": "Uploading...",
  "documents.dropOrClick": "Drop files here or click to upload",
  "documents.supportedTypes": "Supported: TXT, MD, PDF, DOCX, HTML",
  "documents.loadingDocs": "Loading documents...",
  "documents.noDocuments": "No documents uploaded yet",
  "documents.filename": "Filename",
  "documents.type": "Type",
  "documents.size": "Size",
  "documents.chunks": "Chunks",
  "documents.reprocess": "Reprocess",

  "configField.builtin": "Builtin",
  "configField.custom": "Custom",
  "configField.notSet": "Not set",
  "configField.on": "On",
  "configField.off": "Off",
  "configField.unlimited": "Unlimited",

  "assistants.title": "Assistant List",
  "assistants.description": "Configure assistants with models, temperatures, and sampling parameters",
  "assistants.itemName": "assistant",
  "assistants.itemNamePlural": "assistants",
  "assistants.search": "Search assistants...",
  "assistants.col.name": "Name",
  "assistants.col.model": "Model",
  "assistants.col.temperature": "Temperature",
  "assistants.col.maxRounds": "Max Rounds",
  "assistants.col.memory": "Memory",
  "assistants.field.id": "Assistant ID",
  "assistants.field.id.placeholder": "e.g., my-assistant",
  "assistants.field.id.help": "Unique identifier for this assistant",
  "assistants.field.name": "Name",
  "assistants.field.name.placeholder": "My Assistant",
  "assistants.field.icon": "Icon",
  "assistants.field.icon.help": "Choose an icon for this assistant",
  "assistants.field.description": "Description",
  "assistants.field.description.placeholder": "Optional description",
  "assistants.field.description.help": "Brief description of this assistant",
  "assistants.field.modelId": "Model",
  "assistants.field.modelId.help": "Language model to use for this assistant",
  "assistants.field.systemPrompt": "System Prompt",
  "assistants.field.systemPrompt.placeholder": "Optional system prompt...",
  "assistants.field.systemPrompt.help": "Custom instructions for the assistant",
  "assistants.field.temperature": "Temperature",
  "assistants.field.temperature.help": "Controls randomness in responses",
  "assistants.field.temperature.minLabel": "0.0 (Precise)",
  "assistants.field.temperature.maxLabel": "2.0 (Creative)",
  "assistants.field.maxTokens": "Max Tokens",
  "assistants.field.maxTokens.help": "Max output tokens (empty = provider default)",
  "assistants.field.topP": "Top P",
  "assistants.field.topP.help": "Top-p nucleus sampling (empty = provider default)",
  "assistants.field.topK": "Top K",
  "assistants.field.topK.help": "Top-k sampling (empty = provider default)",
  "assistants.field.frequencyPenalty": "Frequency Penalty",
  "assistants.field.frequencyPenalty.help": "Frequency penalty (empty = provider default)",
  "assistants.field.presencePenalty": "Presence Penalty",
  "assistants.field.presencePenalty.help": "Presence penalty (empty = provider default)",
  "assistants.field.maxRounds": "Max Rounds",
  "assistants.field.maxRounds.placeholder": "-1 for unlimited",
  "assistants.field.maxRounds.help": "-1 or empty = unlimited conversation rounds",
  "assistants.field.enabled": "Enable this assistant",
  "assistants.field.memoryEnabled": "Enable assistant memory",
  "assistants.field.knowledgeBases": "Knowledge Bases",
  "assistants.field.knowledgeBases.help": "Select knowledge bases to use for RAG with this assistant",

  "models.title": "Model List",
  "models.description": "Manage language models from different providers",
  "models.itemName": "model",
  "models.itemNamePlural": "models",
  "models.search": "Search models...",
  "models.col.name": "Name",
  "models.col.provider": "Provider",
  "models.col.modelId": "Model ID",
  "models.col.group": "Group",
  "models.field.id": "Model ID",
  "models.field.id.placeholder": "e.g., gpt-4",
  "models.field.id.help": "Model identifier as used by the provider",
  "models.field.providerId": "Provider",
  "models.field.providerId.help": "Provider that hosts this model",
  "models.field.name": "Display Name",
  "models.field.name.placeholder": "GPT-4",
  "models.field.name.help": "Human-readable name for this model",
  "models.field.group": "Group",
  "models.field.group.placeholder": "e.g., gpt-4",
  "models.field.group.help": "Model family or group",
  "models.field.enabled": "Enable this model",

  "providers.title": "Provider List",
  "providers.description": "Manage LLM providers (DeepSeek, OpenAI, Anthropic, etc.)",
  "providers.itemName": "provider",
  "providers.itemNamePlural": "providers",
  "providers.search": "Search providers...",
  "providers.col.name": "Name",
  "providers.col.providerId": "Provider ID",
  "providers.col.apiKey": "API Key",
  "providers.col.baseUrl": "Base URL",
  "providers.field.id": "Provider ID",
  "providers.field.id.placeholder": "e.g., my-openai",
  "providers.field.id.help": "Unique identifier for this provider",
  "providers.field.name": "Display Name",
  "providers.field.name.placeholder": "My OpenAI Provider",
  "providers.field.protocol": "API Protocol",
  "providers.field.protocol.help": "API protocol used by this provider",
  "providers.field.baseUrl": "Base URL",
  "providers.field.baseUrl.placeholder": "https://api.openai.com/v1",
  "providers.field.baseUrl.help": "API endpoint base URL",
  "providers.field.apiKey": "API Key",
  "providers.field.apiKey.placeholder": "sk-...",
  "providers.field.apiKey.help": "API key for authentication (stored in ~/.lex_mint/keys_config.yaml)",
  "providers.field.apiKey.editHelp": "API key for authentication (leave unchanged if masked)",
  "providers.field.enabled": "Enable this provider",

  "knowledgeBases.title": "Knowledge Bases",
  "knowledgeBases.description": "Manage knowledge bases for RAG (Retrieval-Augmented Generation)",
  "knowledgeBases.itemName": "knowledge base",
  "knowledgeBases.itemNamePlural": "knowledge bases",
  "knowledgeBases.search": "Search knowledge bases...",
  "knowledgeBases.col.name": "Name",
  "knowledgeBases.col.documents": "Documents",
  "knowledgeBases.col.created": "Created",
  "knowledgeBases.field.id": "Knowledge Base ID",
  "knowledgeBases.field.id.placeholder": "e.g., my-knowledge-base",
  "knowledgeBases.field.id.help": "Unique identifier for this knowledge base",
  "knowledgeBases.field.name": "Name",
  "knowledgeBases.field.name.placeholder": "My Knowledge Base",
  "knowledgeBases.field.description": "Description",
  "knowledgeBases.field.description.placeholder": "Optional description",
  "knowledgeBases.field.description.help": "Brief description of this knowledge base",
  "knowledgeBases.field.embeddingModel": "Embedding Model Override",
  "knowledgeBases.field.embeddingModel.placeholder": "e.g., deepseek:deepseek-chat",
  "knowledgeBases.field.embeddingModel.help": "Override the default embedding model (leave empty to use global RAG config)",
  "knowledgeBases.field.chunkSize": "Chunk Size Override",
  "knowledgeBases.field.chunkSize.placeholder": "e.g., 1000",
  "knowledgeBases.field.chunkSize.help": "Override chunk size for this KB (leave empty to use global RAG config)",
  "knowledgeBases.field.chunkOverlap": "Chunk Overlap Override",
  "knowledgeBases.field.chunkOverlap.placeholder": "e.g., 200",
  "knowledgeBases.field.chunkOverlap.help": "Override chunk overlap for this KB (leave empty to use global RAG config)",
  "knowledgeBases.field.enabled": "Enable this knowledge base",

  "promptTemplates.title": "Prompt Templates",
  "promptTemplates.description": "Manage reusable prompt templates for quick insertion.",
  "promptTemplates.itemName": "template",
  "promptTemplates.itemNamePlural": "templates",
  "promptTemplates.search": "Search templates...",
  "promptTemplates.col.name": "Name",
  "promptTemplates.col.content": "Content",
  "promptTemplates.col.enabled": "Enabled",
  "promptTemplates.field.name": "Name",
  "promptTemplates.field.name.placeholder": "Code Review Template",
  "promptTemplates.field.description": "Description",
  "promptTemplates.field.description.placeholder": "Short summary of when to use this template",
  "promptTemplates.field.content": "Content",
  "promptTemplates.field.content.placeholder": "Write the prompt template here...",
  "promptTemplates.field.variables.label": "Variables",
  "promptTemplates.field.variables.help": "Define variable schema for this template. Keep placeholders in content aligned with variable keys.",
  "promptTemplates.field.variables.empty": "No variables yet. Add one to collect typed input before insertion.",
  "promptTemplates.field.variables.variableLabel": "Variable {{index}}",
  "promptTemplates.field.variables.add": "Add variable",
  "promptTemplates.field.variables.remove": "Remove",
  "promptTemplates.field.variables.key": "Key",
  "promptTemplates.field.variables.keyPlaceholder": "topic",
  "promptTemplates.field.variables.itemLabel": "Label",
  "promptTemplates.field.variables.labelPlaceholder": "Topic",
  "promptTemplates.field.variables.description": "Description",
  "promptTemplates.field.variables.descriptionPlaceholder": "Optional help text shown in fill dialog",
  "promptTemplates.field.variables.type": "Type",
  "promptTemplates.field.variables.required": "Required",
  "promptTemplates.field.variables.default": "Default",
  "promptTemplates.field.variables.defaultPlaceholder": "Optional default value",
  "promptTemplates.field.variables.noDefault": "No default",
  "promptTemplates.field.variables.options": "Options",
  "promptTemplates.field.variables.optionsPlaceholder": "One option per line, comma is also supported",
  "promptTemplates.field.variables.typeOptions.text": "Text",
  "promptTemplates.field.variables.typeOptions.number": "Number",
  "promptTemplates.field.variables.typeOptions.boolean": "Boolean",
  "promptTemplates.field.variables.typeOptions.select": "Select",
  "promptTemplates.field.variables.error": "Variables must be a valid list.",
  "promptTemplates.field.variables.errorKey": "Each variable needs a key matching ^[A-Za-z_][A-Za-z0-9_]*$.",
  "promptTemplates.field.variables.errorReserved": "The key \"cursor\" is reserved.",
  "promptTemplates.field.variables.errorDuplicate": "Variable keys must be unique.",
  "promptTemplates.field.variables.errorType": "Variable type must be text, number, boolean, or select.",
  "promptTemplates.field.variables.errorSelectOptions": "Select variables must define at least one option.",
  "promptTemplates.field.variables.errorOptionsOnlySelect": "Only select variables can define options.",
  "promptTemplates.field.variables.errorDefaultType": "Default value type does not match variable type.",
  "promptTemplates.field.variables.errorSelectDefault": "Select default value must be one of its options.",
  "promptTemplates.field.enabled": "Enabled",

  "rag.title": "RAG Settings",
  "rag.description": "Configure Retrieval-Augmented Generation (embedding, chunking, and retrieval)",
  "rag.field.vectorStoreBackend": "Vector Store Backend",
  "rag.field.vectorStoreBackend.help": "Choose where RAG vectors are stored.",
  "rag.opt.vectorStoreSqliteVec": "SQLite Vec (recommended)",
  "rag.opt.vectorStoreChroma": "ChromaDB",
  "rag.field.vectorSqlitePath": "SQLite Vector DB Path",
  "rag.field.vectorSqlitePath.placeholder": "e.g., data/state/rag_vec.sqlite3",
  "rag.field.vectorSqlitePath.help": "SQLite file used for vector chunks. Relative paths are resolved from repo root.",
  "rag.field.chromaPersistDirectory": "Chroma Persist Directory",
  "rag.field.chromaPersistDirectory.placeholder": "e.g., data/chromadb",
  "rag.field.chromaPersistDirectory.help": "Directory used by ChromaDB when backend is set to ChromaDB.",
  "rag.field.embeddingProvider": "Embedding Provider",
  "rag.field.embeddingProvider.help": "Select the embedding provider for vector generation",
  "rag.opt.api": "API-based (uses configured LLM provider)",
  "rag.opt.local": "Local (sentence-transformers, requires install)",
  "rag.opt.localGguf": "Local GGUF (llama.cpp)",
  "rag.field.embeddingApiModel": "API Embedding Model",
  "rag.field.embeddingApiModel.placeholder": "e.g., jina-embeddings-v3 or provider:model",
  "rag.field.embeddingApiModel.help": "Model name for embeddings. Use provider:model format to fall back to LLM provider config.",
  "rag.field.embeddingApiBaseUrl": "Embedding API Base URL",
  "rag.field.embeddingApiBaseUrl.placeholder": "e.g., https://api.jina.ai/v1",
  "rag.field.embeddingApiBaseUrl.help": "Base URL for the embedding API. Leave empty to use LLM provider base URL.",
  "rag.field.embeddingApiKey": "Embedding API Key",
  "rag.field.embeddingApiKey.placeholder": "Enter API key for embedding service",
  "rag.field.embeddingApiKey.help": "API key for the embedding service. Leave empty to use LLM provider API key.",
  "rag.field.embeddingLocalModel": "Local Model Name",
  "rag.field.embeddingLocalModel.placeholder": "e.g., all-MiniLM-L6-v2",
  "rag.field.embeddingLocalModel.help": "HuggingFace model name for local embeddings",
  "rag.field.embeddingLocalDevice": "Local Device",
  "rag.field.embeddingLocalDevice.help": "Device for running local embedding model",
  "rag.field.embeddingLocalGgufModelPath": "GGUF Model Path",
  "rag.field.embeddingLocalGgufModelPath.placeholder": "e.g., models/embeddings/qwen3-embedding-0.6b.gguf",
  "rag.field.embeddingLocalGgufModelPath.help": "Path to the local GGUF embedding model. Relative paths are resolved from repo root.",
  "rag.field.embeddingLocalGgufCtx": "GGUF Context Length",
  "rag.field.embeddingLocalGgufCtx.help": "llama.cpp context size (n_ctx). Increase if your chunks are long.",
  "rag.field.embeddingLocalGgufThreads": "GGUF CPU Threads",
  "rag.field.embeddingLocalGgufThreads.help": "CPU thread count (0 = auto).",
  "rag.field.embeddingLocalGgufGpuLayers": "GGUF GPU Layers",
  "rag.field.embeddingLocalGgufGpuLayers.help": "Number of layers to offload to GPU (0 = CPU only).",
  "rag.field.embeddingLocalGgufNormalize": "Normalize Embeddings",
  "rag.field.embeddingLocalGgufNormalize.help": "Apply L2 normalization before writing vectors.",
  "rag.field.embeddingBatchSize": "Embedding Batch Size",
  "rag.field.embeddingBatchSize.help": "Number of chunks per embedding API call. Increase for faster processing if your API allows it.",
  "rag.field.embeddingBatchDelaySeconds": "Batch Delay (seconds)",
  "rag.field.embeddingBatchDelaySeconds.help": "Delay between batch API calls to avoid rate limits. Reduce for faster processing with premium API access.",
  "rag.field.embeddingBatchMaxRetries": "Batch Max Retries",
  "rag.field.embeddingBatchMaxRetries.help": "Number of retries for failed embedding batch calls before giving up.",
  "rag.field.chunkSize": "Default Chunk Size",
  "rag.field.chunkSize.help": "Default size for text chunks (characters)",
  "rag.field.chunkOverlap": "Default Chunk Overlap",
  "rag.field.chunkOverlap.help": "Default overlap between adjacent chunks (characters)",
  "rag.field.retrievalMode": "Retrieval Mode",
  "rag.field.retrievalMode.help": "Choose vector-only, BM25-only, or hybrid retrieval.",
  "rag.opt.retrievalVector": "Vector Only",
  "rag.opt.retrievalBm25": "BM25 Only",
  "rag.opt.retrievalHybrid": "Hybrid (Vector + BM25)",
  "rag.field.topK": "Top K Results",
  "rag.field.topK.help": "Number of top results to retrieve from knowledge base",
  "rag.field.recallK": "Recall K Candidates",
  "rag.field.recallK.help": "Candidate pool size before dedup/diversity/reorder. Should be >= Top K.",
  "rag.field.vectorRecallK": "Vector Recall K",
  "rag.field.vectorRecallK.help": "Vector candidate pool size before fusion/rerank.",
  "rag.field.bm25RecallK": "BM25 Recall K",
  "rag.field.bm25RecallK.help": "BM25 candidate pool size before fusion/rerank.",
  "rag.field.fusionTopK": "Fusion Top K",
  "rag.field.fusionTopK.help": "Maximum fused candidates kept before reranking.",
  "rag.field.fusionStrategy": "Fusion Strategy",
  "rag.field.fusionStrategy.help": "How vector and BM25 ranks are combined.",
  "rag.opt.fusionRrf": "RRF (Reciprocal Rank Fusion)",
  "rag.field.rrfK": "RRF K",
  "rag.field.rrfK.help": "RRF denominator offset; larger values smooth rank differences.",
  "rag.field.vectorWeight": "Vector Weight",
  "rag.field.vectorWeight.help": "Weight of vector rank contribution in hybrid fusion.",
  "rag.field.bm25Weight": "BM25 Weight",
  "rag.field.bm25Weight.help": "Weight of BM25 rank contribution in hybrid fusion.",
  "rag.field.maxPerDoc": "Max Chunks Per Document",
  "rag.field.maxPerDoc.help": "Maximum chunks selected from the same document for one turn. Set to 0 to disable this limit.",
  "rag.field.scoreThreshold": "Score Threshold",
  "rag.field.scoreThreshold.help": "Minimum similarity score for results (0-1)",
  "rag.field.reorderStrategy": "Reorder Strategy",
  "rag.field.reorderStrategy.help": "How selected chunks are reordered before prompt injection.",
  "rag.opt.longContext": "Long Context (edge-biased)",
  "rag.opt.none": "None (keep score order)",
  "rag.field.rerankEnabled": "Enable Reranker",
  "rag.field.rerankEnabled.help": "Apply model-based reranking to recalled candidates before final selection.",
  "rag.field.rerankApiModel": "Rerank Model",
  "rag.field.rerankApiModel.placeholder": "e.g., jina-reranker-v2-base-multilingual",
  "rag.field.rerankApiModel.help": "Model ID used by the rerank API endpoint.",
  "rag.field.rerankApiBaseUrl": "Rerank API URL",
  "rag.field.rerankApiBaseUrl.placeholder": "e.g., https://api.jina.ai/v1/rerank",
  "rag.field.rerankApiBaseUrl.help": "Full endpoint URL for rerank requests.",
  "rag.field.rerankApiKey": "Rerank API Key",
  "rag.field.rerankApiKey.placeholder": "Enter API key for rerank service",
  "rag.field.rerankApiKey.help": "Optional for local endpoints. Sent as Bearer token when provided.",
  "rag.field.rerankTimeoutSeconds": "Rerank Timeout (seconds)",
  "rag.field.rerankTimeoutSeconds.help": "Maximum wait time for rerank response.",
  "rag.field.rerankWeight": "Rerank Weight",
  "rag.field.rerankWeight.help": "Blend ratio for final score: rerank_weight * rerank + (1-rerank_weight) * vector score.",
  "rag.field.retrievalPreset": "Retrieval Preset",
  "rag.field.retrievalPreset.help": "One-click presets for common retrieval configurations. Individual values can still be adjusted after selecting a preset.",
  "rag.opt.presetFast": "Fast",
  "rag.opt.presetFast.desc": "Low latency, fewer results",
  "rag.opt.presetBalanced": "Balanced",
  "rag.opt.presetBalanced.desc": "Good coverage, moderate cost",
  "rag.opt.presetDeep": "Deep",
  "rag.opt.presetDeep.desc": "Maximum recall, higher latency",

  "search.title": "Search Settings",
  "search.description": "Choose a search provider for the chat web search toggle",
  "search.field.provider": "Search Provider",
  "search.field.provider.help": "Select the search provider for web searches",
  "search.opt.duckduckgo": "DuckDuckGo (Free, no API key required)",
  "search.opt.tavily": "Tavily (Higher quality, requires API key)",
  "search.field.maxResults": "Max Results",
  "search.field.maxResults.help": "Maximum number of search results to return",
  "search.field.timeout": "Timeout (seconds)",
  "search.field.timeout.help": "Maximum time to wait for search results",

  "titleGen.title": "Title Generation Settings",
  "titleGen.description": "Configure automatic conversation title generation using a small language model",
  "titleGen.field.enabled": "Enable automatic title generation",
  "titleGen.field.triggerThreshold": "Trigger Threshold (conversation rounds)",
  "titleGen.field.triggerThreshold.help": "Generate title after this many conversation rounds (1 round = user message + assistant response)",
  "titleGen.field.modelId": "Small Model for Title Generation",
  "titleGen.field.modelId.help": "Recommended: Use a small, fast model like GPT-4o-mini to minimize cost",
  "titleGen.field.maxContextRounds": "Max Context Rounds",
  "titleGen.field.maxContextRounds.help": "Maximum number of recent conversation rounds to use as context",
  "titleGen.field.timeout": "Timeout (seconds)",
  "titleGen.field.timeout.help": "Maximum time to wait for title generation",
  "titleGen.field.promptTemplate": "Prompt Template",
  "titleGen.field.promptTemplate.placeholder": "Enter prompt template. Use {conversation_text} as placeholder for conversation content.",
  "titleGen.field.promptTemplate.help": "Use {conversation_text} as a placeholder for the actual conversation content",

  "webpage.title": "Webpage Settings",
  "webpage.description": "Configure webpage fetch and proxy settings",
  "webpage.field.enabled": "Enable webpage fetching",
  "webpage.field.maxUrls": "Max URLs per request",
  "webpage.field.maxUrls.help": "Maximum number of URLs to fetch in a single request",
  "webpage.field.timeout": "Timeout (seconds)",
  "webpage.field.timeout.help": "Maximum time to wait for webpage fetch",
  "webpage.field.maxBytes": "Max Download Size (bytes)",
  "webpage.field.maxBytes.help": "Maximum size of webpage to download",
  "webpage.field.maxContentChars": "Max Content Characters",
  "webpage.field.maxContentChars.help": "Maximum length of extracted text content",
  "webpage.field.userAgent": "User Agent",
  "webpage.field.userAgent.placeholder": "lex_mint/1.0",
  "webpage.field.userAgent.help": "Custom User-Agent header for requests",
  "webpage.field.proxy": "Proxy URL",
  "webpage.field.proxy.placeholder": "http://proxy.example.com:8080",
  "webpage.field.proxy.help": "HTTP/HTTPS proxy URL (leave empty to disable)",
  "webpage.field.trustEnv": "Trust environment proxy settings",
  "webpage.field.diagnosticsEnabled": "Enable network diagnostics",
  "webpage.field.diagnosticsTimeout": "Diagnostics Timeout (seconds)",
  "webpage.field.diagnosticsTimeout.help": "Timeout for network diagnostics checks",

  "followup.title": "Follow-up Questions Settings",
  "followup.description": "Configure automatic follow-up question suggestions after each chat response",
  "followup.field.enabled": "Enable follow-up question suggestions",
  "followup.field.count": "Number of Suggestions",
  "followup.field.count.help": "How many follow-up questions to generate (0 to disable)",
  "followup.field.modelId": "Model for Follow-up Generation",
  "followup.field.modelId.help": "Recommended: Use a small, fast model to minimize latency",
  "followup.field.maxContextRounds": "Max Context Rounds",
  "followup.field.maxContextRounds.help": "Maximum number of recent conversation rounds to use as context",
  "followup.field.timeout": "Timeout (seconds)",
  "followup.field.timeout.help": "Maximum time to wait for follow-up generation",
  "followup.field.promptTemplate": "Prompt Template",
  "followup.field.promptTemplate.placeholder": "Enter prompt template. Use {count} and {conversation_text} as placeholders.",
  "followup.field.promptTemplate.help": "Use {count} for number of questions and {conversation_text} for conversation content",

  "compression.title": "Context Compression Settings",
  "compression.description": "Configure how conversation context is compressed (summarized) to free up the context window",
  "compression.field.provider": "Compression Provider",
  "compression.field.provider.help": "Choose whether summarization uses configured providers or a local GGUF model.",
  "compression.opt.modelConfig": "Configured Provider Model",
  "compression.opt.localGguf": "Local GGUF (llama.cpp)",
  "compression.field.autoCompress": "Enable Auto-Compression",
  "compression.field.outputLanguage": "Compression Output Language",
  "compression.field.outputLanguage.help": "auto = use translation language detection result; none = no language constraint; or force a target language.",
  "compression.opt.outputLanguageAuto": "Auto (Detect)",
  "compression.opt.outputLanguageNone": "None (Unspecified)",
  "compression.opt.outputLanguageZh": "Chinese",
  "compression.opt.outputLanguageEn": "English",
  "compression.opt.outputLanguageJa": "Japanese",
  "compression.opt.outputLanguageKo": "Korean",
  "compression.opt.outputLanguageFr": "French",
  "compression.opt.outputLanguageDe": "German",
  "compression.opt.outputLanguageEs": "Spanish",
  "compression.opt.outputLanguageRu": "Russian",
  "compression.opt.outputLanguagePt": "Portuguese",
  "compression.field.threshold": "Auto-Compression Threshold",
  "compression.field.threshold.help": "Compression triggers when token usage exceeds this ratio of the context window (e.g. 0.5 = 50%)",
  "compression.field.modelId": "Compression Model",
  "compression.field.modelId.help": "Model used to generate the conversation summary. You can also follow the current chat model.",
  "compression.opt.sameAsChatModel": "Same as Current Chat Model",
  "compression.field.localGgufModelPath": "GGUF Model Path",
  "compression.field.localGgufModelPath.placeholder": "e.g., models/llm/local-summarizer.gguf",
  "compression.field.localGgufModelPath.help": "Path to local summary GGUF model. Relative paths are resolved from repo root.",
  "compression.field.localGgufCtx": "GGUF Context Length",
  "compression.field.localGgufCtx.help": "llama.cpp context size (n_ctx). Increase for longer chat histories.",
  "compression.field.localGgufThreads": "GGUF CPU Threads",
  "compression.field.localGgufThreads.help": "CPU thread count (0 = auto).",
  "compression.field.localGgufGpuLayers": "GGUF GPU Layers",
  "compression.field.localGgufGpuLayers.help": "Number of layers to offload to GPU (0 = CPU only).",
  "compression.field.localGgufMaxTokens": "GGUF Max Output Tokens",
  "compression.field.localGgufMaxTokens.help": "Maximum generated tokens for one summarization call.",
  "compression.field.strategy": "Compression Strategy",
  "compression.field.strategy.help": "For local GGUF, choose single-pass or hierarchical map/reduce compression.",
  "compression.opt.hierarchical": "Hierarchical (Map/Reduce)",
  "compression.opt.singlePass": "Single Pass",
  "compression.field.hierChunkTargetTokens": "Chunk Target Tokens",
  "compression.field.hierChunkTargetTokens.help": "Target input tokens per chunk in map stage. 0 = auto.",
  "compression.field.hierChunkOverlapMessages": "Chunk Overlap Messages",
  "compression.field.hierChunkOverlapMessages.help": "How many messages overlap between adjacent chunks.",
  "compression.field.hierReduceTargetTokens": "Reduce Target Tokens",
  "compression.field.hierReduceTargetTokens.help": "Target input tokens per reduce group. 0 = auto.",
  "compression.field.hierReduceOverlapItems": "Reduce Overlap Items",
  "compression.field.hierReduceOverlapItems.help": "How many partial summaries overlap between reduce groups.",
  "compression.field.hierMaxLevels": "Max Hierarchy Levels",
  "compression.field.hierMaxLevels.help": "Hard cap for reduce rounds to prevent endless compression loops.",
  "compression.field.qualityGuardEnabled": "Enable Quality Guard",
  "compression.field.qualityGuardMinCoverage": "Quality Guard Min Coverage",
  "compression.field.qualityGuardMinCoverage.help": "Minimum coverage ratio for detected critical facts in the final summary.",
  "compression.field.qualityGuardMaxFacts": "Quality Guard Max Facts",
  "compression.field.qualityGuardMaxFacts.help": "Maximum critical facts sampled from source messages during verification.",
  "compression.field.metricsEnabled": "Enable Compression Metrics",
  "compression.field.metricsEnabled.help": "Store compression ratio and latency estimates in summary metadata.",
  "compression.field.temperature": "Temperature",
  "compression.field.temperature.help": "Lower values produce more factual summaries. Recommended: 0.2 - 0.5",
  "compression.field.minMessages": "Minimum Messages to Compress",
  "compression.field.minMessages.help": "Minimum number of messages required before compression is allowed",
  "compression.field.timeout": "Timeout (seconds)",
  "compression.field.timeout.help": "Maximum time to wait for the compression LLM call",
  "compression.field.promptTemplate": "Summarization Prompt",
  "compression.field.promptTemplate.placeholder": "Enter summarization prompt. Use {formatted_messages} as placeholder for conversation content.",
  "compression.field.promptTemplate.help": "Use {formatted_messages} where the conversation text should be inserted",

  "fileReference.title": "File Reference Settings",
  "fileReference.description": "Configure @file preview and context injection limits for chat display and LLM input.",
  "fileReference.field.uiPreviewMaxChars": "UI Preview Max Characters",
  "fileReference.field.uiPreviewMaxChars.help": "Maximum characters shown in file-reference blocks inside chat messages.",
  "fileReference.field.uiPreviewMaxLines": "UI Preview Max Lines",
  "fileReference.field.uiPreviewMaxLines.help": "Maximum lines shown in file-reference blocks inside chat messages.",
  "fileReference.field.injectionPreviewMaxChars": "Injection Preview Max Characters",
  "fileReference.field.injectionPreviewMaxChars.help": "Maximum characters per injected chunk before it is abbreviated.",
  "fileReference.field.injectionPreviewMaxLines": "Injection Preview Max Lines",
  "fileReference.field.injectionPreviewMaxLines.help": "Maximum lines per injected chunk before it is abbreviated.",
  "fileReference.field.chunkSize": "Chunk Size",
  "fileReference.field.chunkSize.help": "Character window used when splitting referenced files into chunks.",
  "fileReference.field.maxChunks": "Max Chunks",
  "fileReference.field.maxChunks.help": "Maximum number of representative chunks injected per referenced file.",
  "fileReference.field.totalBudgetChars": "Total Injection Budget (Chars)",
  "fileReference.field.totalBudgetChars.help": "Total character budget across all referenced files in a single message.",

  "translationConfig.title": "Translation Settings",
  "translationConfig.description": "Configure Q&A translation for translating LLM responses and user input",
  "translationConfig.field.provider": "Translation Provider",
  "translationConfig.field.provider.help": "Choose whether translation uses configured providers or a local GGUF model.",
  "translationConfig.opt.modelConfig": "Configured Provider Model",
  "translationConfig.opt.localGguf": "Local GGUF (llama.cpp)",
  "translationConfig.field.enabled": "Enable Translation",
  "translationConfig.field.enabled.help": "Enable or disable the translation feature",
  "translationConfig.field.targetLanguage": "Response Translation Language",
  "translationConfig.field.targetLanguage.help": "Language to translate LLM responses into (e.g., Chinese, Japanese, Korean)",
  "translationConfig.field.inputTargetLanguage": "Input Translation Language",
  "translationConfig.field.inputTargetLanguage.help": "Language to translate user input into before sending to LLM (e.g., English)",
  "translationConfig.field.modelId": "Translation Model",
  "translationConfig.field.modelId.help": "Model used for translation. A fast model is recommended.",
  "translationConfig.field.localGgufModelPath": "GGUF Model Path",
  "translationConfig.field.localGgufModelPath.placeholder": "e.g., models/llm/local-translate.gguf",
  "translationConfig.field.localGgufModelPath.help": "Path to local translation GGUF model. Relative paths are resolved from repo root.",
  "translationConfig.field.localGgufCtx": "GGUF Context Length",
  "translationConfig.field.localGgufCtx.help": "llama.cpp context size (n_ctx). Increase for longer inputs.",
  "translationConfig.field.localGgufThreads": "GGUF CPU Threads",
  "translationConfig.field.localGgufThreads.help": "CPU thread count (0 = auto).",
  "translationConfig.field.localGgufGpuLayers": "GGUF GPU Layers",
  "translationConfig.field.localGgufGpuLayers.help": "Number of layers to offload to GPU (0 = CPU only).",
  "translationConfig.field.localGgufMaxTokens": "GGUF Max Output Tokens",
  "translationConfig.field.localGgufMaxTokens.help": "Maximum generated tokens for one translation call.",
  "translationConfig.field.temperature": "Temperature",
  "translationConfig.field.temperature.help": "Lower values produce more accurate translations. Recommended: 0.1 - 0.5",
  "translationConfig.field.timeout": "Timeout (seconds)",
  "translationConfig.field.timeout.help": "Maximum time to wait for the translation LLM call",
  "translationConfig.field.promptTemplate": "Translation Prompt",
  "translationConfig.field.promptTemplate.placeholder": "Enter translation prompt. Use {text} and {target_language} as placeholders.",
  "translationConfig.field.promptTemplate.help": "Use {text} for the content to translate and {target_language} for the target language",

  "tts.title": "Text-to-Speech Settings",
  "tts.description": "Configure text-to-speech synthesis using Edge TTS (Microsoft neural voices)",
  "tts.field.enabled": "Enable TTS",
  "tts.field.enabled.help": "Enable or disable the text-to-speech feature",
  "tts.field.voice": "Default Voice",
  "tts.field.voice.help": "Edge TTS voice for English and other languages (e.g., en-US-AriaNeural, en-US-GuyNeural)",
  "tts.field.voiceZh": "Chinese Voice",
  "tts.field.voiceZh.help": "Edge TTS voice for Chinese text (e.g., zh-CN-XiaoxiaoNeural, zh-CN-YunxiNeural). Auto-selected when Chinese text is detected.",
  "tts.field.rate": "Speech Rate",
  "tts.field.rate.help": "Speech rate adjustment (e.g., +0%, +20%, -10%)",
  "tts.field.volume": "Volume",
  "tts.field.volume.help": "Volume adjustment (e.g., +0%, +50%, -20%)",
  "tts.field.maxTextLength": "Max Text Length",
  "tts.field.maxTextLength.help": "Maximum number of characters to synthesize. Longer text will be truncated."
}
